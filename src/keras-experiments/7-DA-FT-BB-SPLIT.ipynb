{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing import image_dataset_from_directory\n","from keras.preprocessing.image import ImageDataGenerator\n","import tensorflow_addons as tfa\n","from functools import partial\n","from numpy.random import default_rng\n","import matplotlib.pyplot as plt\n","rng = default_rng()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["SEED = 42\n","PROJECT_FOLDER = \"../hotel_recog_splitted/bed\"\n","TRAIN_DATA_FOLDER = PROJECT_FOLDER\n","\n","IMAGE_SIZE = (224, 224)\n","input_size = 224\n","VAL_SPLIT = 0.1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T12:47:38.525646Z","iopub.status.busy":"2022-04-25T12:47:38.525401Z","iopub.status.idle":"2022-04-25T12:47:46.354893Z","shell.execute_reply":"2022-04-25T12:47:46.352698Z","shell.execute_reply.started":"2022-04-25T12:47:38.525619Z"},"trusted":true},"outputs":[],"source":["train_ds = image_dataset_from_directory(\n","    directory=TRAIN_DATA_FOLDER,\n","    labels='inferred',\n","    label_mode='categorical',\n","    batch_size=10,\n","    seed=1337,\n","    image_size=IMAGE_SIZE,\n","    crop_to_aspect_ratio=True,\n","    subset='training',\n","    validation_split=VAL_SPLIT\n",")\n","\n","val_ds = image_dataset_from_directory(\n","    directory=TRAIN_DATA_FOLDER,\n","    labels='inferred',\n","    label_mode='categorical',\n","    batch_size=10,\n","    seed=1337,\n","    image_size=IMAGE_SIZE,\n","    crop_to_aspect_ratio=True,\n","    subset='validation',\n","    validation_split=VAL_SPLIT\n",")\n","\n","# test_ds = image_dataset_from_directory(\n","#     directory=TEST_DATA_FOLDER,\n","#     labels=None,\n","#     batch_size=1,\n","#     seed=1337,\n","#     image_size=IMAGE_SIZE,\n","#     crop_to_aspect_ratio=True,\n","# )\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n_classes = len(train_ds.class_names)\n","n_classes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def augment_using_ops(images, labels):\n","    images = tf.image.random_flip_left_right(images)\n","    images = tf.image.random_brightness(images, 0.2)\n","    images = tf.image.random_contrast(images, 0.1, 0.6)\n","    return (images, labels)\n","\n","train_ds_aug = train_ds.map(augment_using_ops)\n","val_ds_aug = train_ds.map(augment_using_ops)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def random_cutout(images_tensor, labels):\n","    ratios_x = rng.uniform(0.1, 0.4)*images_tensor.shape[1]\n","    ratios_y = rng.uniform(0.1, 0.4)*images_tensor.shape[2]\n","\n","    xs_mask = tf.cast(ratios_x, tf.int32)\n","    xs_mask = xs_mask if xs_mask % 2 == 0 else xs_mask+1 # force number even\n","\n","    ys_mask = tf.cast(ratios_y, tf.int32)\n","    ys_mask = ys_mask if ys_mask % 2 == 0 else ys_mask+1 # force number even\n","\n","    return tfa.image.random_cutout(images_tensor, (xs_mask, ys_mask), constant_values = (255.0, 0.0, 0.0)), labels\n","\n","train_ds_aug = train_ds_aug.map(random_cutout)\n","val_ds_aug = val_ds_aug.map(random_cutout)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["a = next(iter(train_ds_aug))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.imshow(a[0][0]/255.0)"]},{"cell_type":"markdown","metadata":{},"source":["# Models"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_finetuned_efficientnet_model(n_classes):\n","    efficientnet_layer = tf.keras.applications.EfficientNetB0(\n","            include_top= False,\n","            weights=\"imagenet\")\n","    efficientnet_layer.trainable = False\n","    \n","    model = keras.Sequential([\n","        efficientnet_layer,\n","        keras.layers.GlobalAveragePooling2D(name = \"avg_pool\"),\n","        keras.layers.BatchNormalization(),\n","        keras.layers.Dropout(0.2),\n","        keras.layers.Dense(n_classes, activation = 'softmax')\n","    ])\n","    \n","    model.compile(\n","        optimizer= tf.keras.optimizers.Adam(learning_rate=1e-2),\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy']\n","    )\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_unfreezed_efficientnet_model(model):\n","    for layer in model.layers[-35:]:\n","        if not isinstance(layer, keras.layers.BatchNormalization):\n","            layer.trainable = True\n","    \n","    model.compile(\n","        optimizer= tf.keras.optimizers.Adam(learning_rate=1e-4),\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy']\n","    )\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = create_finetuned_efficientnet_model(n_classes)\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["callbacks = [\n","    tf.keras.callbacks.TensorBoard(\n","        log_dir = 'logs'\n","    ), \n","    tf.keras.callbacks.ModelCheckpoint(\n","        filepath='ckp',\n","        save_weights_only=True,\n","        monitor='val_accuracy',\n","        mode='max',\n","        save_best_only=True),\n","    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["history = model.fit(train_ds_aug, epochs=10, callbacks=callbacks, validation_data=val_ds_aug)\n","model.save('../models/bedroom_finetune_part1.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = tf.keras.models.load_model('../models/bedroom_finetune_part1.h5')\n","model.load_weights('ckp')\n","\n","model = create_unfreezed_efficientnet_model(model)\n","history2 = model.fit(train_ds_aug, epochs=20, callbacks=callbacks, validation_data=val_ds_aug)\n","model.save('../models/bedroom_finetune_part2.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["metrics = history.history\n","plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n","plt.legend(['loss', 'val_loss'])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["metrics = history2.history\n","plt.plot(history2.epoch, metrics['loss'], metrics['val_loss'])\n","plt.legend(['loss', 'val_loss'])\n","plt.show()"]}],"metadata":{"interpreter":{"hash":"b6d4e993f1ddc8d1cfe67913a896d10f450ad28d542a4b26c75cc69fb32cc64c"},"kernelspec":{"display_name":"Python 3.9.12 ('tf')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":4}
