{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/html":["\n","      <iframe id=\"tensorboard-frame-812f14108750a4b9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n","      </iframe>\n","      <script>\n","        (function() {\n","          const frame = document.getElementById(\"tensorboard-frame-812f14108750a4b9\");\n","          const url = new URL(\"/\", window.location);\n","          const port = 6006;\n","          if (port) {\n","            url.port = port;\n","          }\n","          frame.src = url;\n","        })();\n","      </script>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["%load_ext tensorboard\n","%tensorboard --logdir logs"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing import image_dataset_from_directory\n","import tensorflow_addons as tfa\n","from numpy.random import default_rng\n","rng = default_rng()\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"module 'tensorflow' has no attribute 'Session'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Pedro\\OneDrive\\Documentos\\1ยบ Data Science\\ML\\project 2\\mlip-hotel-id\\src\\4-finetuning_b4.ipynb Cell 3'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Pedro/OneDrive/Documentos/1%C2%BA%20Data%20Science/ML/project%202/mlip-hotel-id/src/4-finetuning_b4.ipynb#ch0000015?line=2'>3</a>\u001b[0m     b \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant([\u001b[39m1.0\u001b[39m, \u001b[39m2.0\u001b[39m, \u001b[39m3.0\u001b[39m, \u001b[39m4.0\u001b[39m, \u001b[39m5.0\u001b[39m, \u001b[39m6.0\u001b[39m], shape\u001b[39m=\u001b[39m[\u001b[39m3\u001b[39m, \u001b[39m2\u001b[39m], name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Pedro/OneDrive/Documentos/1%C2%BA%20Data%20Science/ML/project%202/mlip-hotel-id/src/4-finetuning_b4.ipynb#ch0000015?line=3'>4</a>\u001b[0m     c \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mmatmul(a, b)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Pedro/OneDrive/Documentos/1%C2%BA%20Data%20Science/ML/project%202/mlip-hotel-id/src/4-finetuning_b4.ipynb#ch0000015?line=5'>6</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39;49mSession() \u001b[39mas\u001b[39;00m sess:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Pedro/OneDrive/Documentos/1%C2%BA%20Data%20Science/ML/project%202/mlip-hotel-id/src/4-finetuning_b4.ipynb#ch0000015?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m (sess\u001b[39m.\u001b[39mrun(c))\n","\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"]}],"source":["print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["SEED = 42\n","PROJECT_FOLDER = \"../input/hotel-id-to-combat-human-trafficking-2022-fgvc9/\"\n","TRAIN_DATA_FOLDER = PROJECT_FOLDER + \"train_images/\"\n","TEST_DATA_FOLDER = PROJECT_FOLDER + \"test_images/\"\n","\n","IMAGE_SIZE = (380, 380)\n","VAL_SPLIT = 0.1"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2022-04-25T12:47:38.525646Z","iopub.status.busy":"2022-04-25T12:47:38.525401Z","iopub.status.idle":"2022-04-25T12:47:46.354893Z","shell.execute_reply":"2022-04-25T12:47:46.352698Z","shell.execute_reply.started":"2022-04-25T12:47:38.525619Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 2081 files belonging to 100 classes.\n","Using 1873 files for training.\n","Found 2081 files belonging to 100 classes.\n","Using 208 files for validation.\n","Found 1 files belonging to 1 classes.\n"]}],"source":["train_ds = image_dataset_from_directory(\n","    directory=TRAIN_DATA_FOLDER,\n","    labels='inferred',\n","    label_mode='categorical',\n","    batch_size=32,\n","    seed=1337,\n","    image_size=IMAGE_SIZE,\n","    crop_to_aspect_ratio=True,\n","    subset='training',\n","    validation_split=VAL_SPLIT\n",")\n","\n","val_ds = image_dataset_from_directory(\n","    directory=TRAIN_DATA_FOLDER,\n","    labels='inferred',\n","    label_mode='categorical',\n","    batch_size=32,\n","    seed=1337,\n","    image_size=IMAGE_SIZE,\n","    crop_to_aspect_ratio=True,\n","    subset='validation',\n","    validation_split=VAL_SPLIT\n",")\n","\n","test_ds = image_dataset_from_directory(\n","    directory=TEST_DATA_FOLDER,\n","    labels=None,\n","    batch_size=1,\n","    seed=1337,\n","    image_size=IMAGE_SIZE,\n","    crop_to_aspect_ratio=True,\n",")"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"text/plain":["100"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["n_classes = len(train_ds.class_names)\n","n_classes"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["def random_cutout(images_tensor, labels):\n","    ratios_x = rng.uniform(0.2, 0.6)*images_tensor.shape[1]\n","    ratios_y = rng.uniform(0.2, 0.6)*images_tensor.shape[2]\n","\n","    xs_mask = tf.cast(ratios_x, tf.int32)\n","    xs_mask = xs_mask if xs_mask % 2 == 0 else xs_mask+1 # force number even\n","\n","    ys_mask = tf.cast(ratios_y, tf.int32)\n","    ys_mask = ys_mask if ys_mask % 2 == 0 else ys_mask+1 # force number even\n","\n","    return tfa.image.random_cutout(images_tensor, (xs_mask, ys_mask), constant_values = (255.0, 0.0, 0.0)), labels\n","\n","train_ds = train_ds.map(random_cutout)\n","val_ds = val_ds.map(random_cutout)"]},{"cell_type":"markdown","metadata":{},"source":["# Models"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["\n","def create_baseline_efficientnet_model(n_classes):\n","    efficientnet_layer = tf.keras.applications.EfficientNetB4(\n","            include_top=True,\n","            weights=\"imagenet\")\n","    efficientnet_layer.trainable = False\n","    \n","    model = keras.Sequential([\n","        efficientnet_layer,\n","        keras.layers.Dropout(0.2),\n","        keras.layers.BatchNormalization(),\n","        keras.layers.Dense(1000, activation='selu'),\n","        keras.layers.Dropout(0.2),\n","        keras.layers.BatchNormalization(),\n","        keras.layers.Dense(1000, activation='selu'),\n","        keras.layers.Dropout(0.2),\n","        keras.layers.BatchNormalization(),\n","        keras.layers.Dense(n_classes, activation='softmax')\n","    ])\n","    \n","    model.compile(\n","        optimizer= tf.keras.optimizers.Adam(learning_rate=1e-2),\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy']\n","    )\n","    return model\n","  \n"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["def create_finetuned_efficientnet_model(n_classes):\n","    efficientnet_layer = tf.keras.applications.EfficientNetB4(\n","            include_top= False,\n","            weights=\"imagenet\")\n","    efficientnet_layer.trainable = False\n","    \n","    model = keras.Sequential([\n","        efficientnet_layer,\n","        keras.layers.GlobalAveragePooling2D(name = \"avg_pool\"),\n","        keras.layers.BatchNormalization(),\n","        keras.layers.Dropout(0.2),\n","        keras.layers.Dense(n_classes, activation = 'softmax')\n","    ])\n","    \n","    model.compile(\n","        optimizer= tf.keras.optimizers.Adam(learning_rate=1e-2),\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy']\n","    )\n","    return model"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["def create_unfreezed_efficientnet_model(model):\n","    for layer in model.layers[-12:]:\n","        if not isinstance(layer, keras.layers.BatchNormalization):\n","            layer.trainable = True\n","    \n","    model.compile(\n","        optimizer= tf.keras.optimizers.Adam(learning_rate=1e-4),\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy']\n","    )\n","    \n","    return model"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," efficientnetb0 (Functional)  (None, None, None, 1280)  4049571  \n","                                                                 \n"," avg_pool (GlobalAveragePool  (None, 1280)             0         \n"," ing2D)                                                          \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 1280)             5120      \n"," hNormalization)                                                 \n","                                                                 \n"," dropout_3 (Dropout)         (None, 1280)              0         \n","                                                                 \n"," dense_3 (Dense)             (None, 100)               128100    \n","                                                                 \n","=================================================================\n","Total params: 4,182,791\n","Trainable params: 130,660\n","Non-trainable params: 4,052,131\n","_________________________________________________________________\n"]}],"source":["model = create_finetuned_efficientnet_model(n_classes)\n","model.summary()"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["13/59 [=====>........................] - ETA: 46s - loss: 4.6164 - accuracy: 0.3317"]}],"source":["callbacks = [\n","    tf.keras.callbacks.TensorBoard(\n","        log_dir = 'logs'\n","    ), \n","    tf.keras.callbacks.ModelCheckpoint(\n","        filepath='ckp',\n","        save_weights_only=True,\n","        monitor='val_accuracy',\n","        mode='max',\n","        save_best_only=True),\n","    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n","]\n","\n","\n","history = model.fit(train_ds, epochs=10, callbacks=callbacks, validation_data=val_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["59/59 [==============================] - 244s 4s/step - loss: 2.3977 - accuracy: 0.5665 - val_loss: 3.4451 - val_accuracy: 0.4327\n"]}],"source":["model = create_unfreezed_efficientnet_model(model)\n","history = model.fit(train_ds, epochs=10, callbacks=callbacks, validation_data=val_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n"]},{"data":{"text/plain":["[0.0, 0.0]"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["model.evaluate(test_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.save('empanadanet.h5')"]}],"metadata":{"interpreter":{"hash":"3763ad9f89648d847e6f5401e1219410b4a0054c5a073f5da0c68452446768ec"},"kernelspec":{"display_name":"Python 3.10.1 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.1"}},"nbformat":4,"nbformat_minor":4}
